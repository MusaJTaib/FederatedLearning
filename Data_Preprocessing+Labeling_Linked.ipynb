{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "482cfbf3-41ea-415d-9d68-d3e0ed6d7845",
   "metadata": {},
   "source": [
    "# CHF Shelter Data Federated Learning Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e373d99-6a3e-45d1-af63-e3769bd9c321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "from tqdm.auto import tqdm, trange\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2875f176",
   "metadata": {},
   "outputs": [],
   "source": [
    "LDays = 548\n",
    "Data_Days = 120\n",
    "Data_periods = 5\n",
    "Data_freq='24D'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320ae42a-aef1-4d88-aaf7-eff0e10073b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5049255-5384-483b-8965-3cfb84bde972",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = pd.read_parquet('MergedShelterData-Nov17.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c6bd16-a4b9-4565-9976-fd6146196310",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011b8253-ce4d-4288-bb18-db5361fca9bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa661bc8-acae-4288-ab7f-936a399daa67",
   "metadata": {},
   "source": [
    "## EDA\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802cffce-b139-404d-96d6-a4f72a9355c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Dates: {tbl.Date.min()} to {tbl.Date.max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0403965-e6c5-4e78-a47a-ad52328fcef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nPrsn = len(tbl.ClientId.unique())\n",
    "print(f'{nPrsn} people in the data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c4cea9-45ad-4780-a208-0b63f76eae61",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{len(tbl.Agency.unique())} different shelters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724268c0-32c6-419e-9282-6f68c995f0ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c746d0c-aadc-411a-a4d2-58e750b28052",
   "metadata": {},
   "source": [
    "#### Number of people who use different shelters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4740b8-2b63-4cd8-95d6-77e54e97fe3e",
   "metadata": {},
   "source": [
    "Total Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f59a35c-3986-4caa-9d8c-e107423c3955",
   "metadata": {},
   "outputs": [],
   "source": [
    "nShelter = tbl.groupby('ClientId').progress_apply(lambda x: len(x.Agency.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488e32ed-6861-4d10-a912-623fac205b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_shelter_breakdown(nShelter,nPrsn):\n",
    "    hist = nShelter.value_counts()\n",
    "    for nS in hist.index.sort_values():\n",
    "        print(f'{hist[nS]}/{nPrsn} ({100*hist[nS]/nPrsn:.2f}%) people used {nS} shelters.')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1e2b4e-d37c-4b2b-ae63-1d7f3367c62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_shelter_breakdown(nShelter,nPrsn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41f74fc-b73d-4ad2-9143-0c68a394f51a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "218bcf2f-4d1e-430b-8c30-8b1281ef2113",
   "metadata": {},
   "source": [
    "Heavy System Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2590ee38-2e7f-400d-a30a-2de2a3198783",
   "metadata": {},
   "outputs": [],
   "source": [
    "nStay = tbl.groupby('ClientId').Date.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77f67a0-18a9-4c14-849e-f57f37ca765d",
   "metadata": {},
   "outputs": [],
   "source": [
    "heavyPctl = 0.95\n",
    "heavyIds = nStay.sort_values().iloc[int(nPrsn*heavyPctl):].index.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f555f4ff-98d8-4723-b18d-5fe12d2432be",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_shelter_breakdown(nShelter[heavyIds],len(heavyIds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b51b28a-1755-4c85-88d5-c11593a6c8b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77bce5d3-1f75-4e22-ad0c-258cf193a187",
   "metadata": {},
   "source": [
    "## Labelling\n",
    "---\n",
    "- We'll use cluster based analysis on total stay and total number of stay episode values to label our data set.\n",
    "- More information on this methodology here: https://arxiv.org/abs/2210.13619"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f34257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming tbl is your DataFrame\n",
    "tbl['Date'] = pd.to_datetime(tbl['Date'])\n",
    "\n",
    "def filter_group(group):\n",
    "    group = group.sort_values('Date')\n",
    "    min_date = group['Date'].min()\n",
    "    # Keep only dates within the first 90 days\n",
    "    group = group[group['Date'] <= min_date + pd.Timedelta(days=LDays)]\n",
    "    # Drop duplicates in the Date column\n",
    "    group = group.drop_duplicates(subset='Date', keep=False)\n",
    "    return group\n",
    "\n",
    "tbl = tbl.groupby('ClientId').apply(filter_group).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b1a9bf-6178-47e5-8f33-e22a400442e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "episodeGap = 30 # days\n",
    "\n",
    "def calc_stays_and_gaps(tbl):    \n",
    "    stayDates = tbl.Date.drop_duplicates().sort_values() \n",
    "    nStay = len(stayDates)\n",
    "\n",
    "    gapVals = stayDates.diff()\n",
    "    nEpi = len(gapVals.loc[gapVals >= pd.Timedelta(f'{episodeGap} day') ])+1\n",
    "    \n",
    "    return pd.Series({ 'NStays': nStay, 'NEpisodes': nEpi })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3501736-bf91-4b3f-b0fd-161a2257ce00",
   "metadata": {},
   "outputs": [],
   "source": [
    "tblStayGap = tbl.groupby('ClientId').progress_apply(calc_stays_and_gaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3e263b-6b0d-4f06-8140-dea47dcfae07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tblStayGap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79e3435-6bab-4db6-9c3a-eed0203625b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_cluster_labels(tbl):\n",
    "    dat = tbl.to_numpy()\n",
    "    nrm = (dat - dat.mean(axis=0))/np.sqrt(dat.var(axis=0))\n",
    "\n",
    "    kmeans = KMeans(n_clusters=3, random_state=0).fit(nrm)\n",
    "    labels = kmeans.labels_    \n",
    "\n",
    "    labelVal = {}\n",
    "    labelVal['Trn'] = np.argmin(kmeans.cluster_centers_.sum(axis=1)) # Transitional: Fewest stays and episodes.\n",
    "    labelVal['Epi'] = np.argmax(kmeans.cluster_centers_[:,1])  # Chronic: Most stays.\n",
    "    labelVal['Chr'] = np.argmax(kmeans.cluster_centers_[:,0])  # Episodic: Most episodes.\n",
    "\n",
    "    print(\"Sum of centroids:\", kmeans.cluster_centers_.sum(axis=1))\n",
    "    print(\"Max in second feature:\", kmeans.cluster_centers_[:, 1])\n",
    "    print(\"Max in first feature:\", kmeans.cluster_centers_[:, 0])\n",
    "\n",
    "    cohort = {}\n",
    "    for k in labelVal.keys():\n",
    "        cohort[k] = tbl.loc[labels == labelVal[k]].index.to_numpy()\n",
    "\n",
    "    return cohort\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebf94b7-a007-4670-a8a6-47b8b9d47554",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_stats(labels):    \n",
    "    nPrsn = 0\n",
    "    for k in labels.keys():\n",
    "        nPrsn += len(labels[k])\n",
    "        \n",
    "    for k in labels.keys():\n",
    "        print(f'{k}: {len(labels[k])}/{nPrsn} ({100*len(labels[k])/nPrsn:.2f}%)')        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb1a896-45e1-4525-b0de-c5e19fe1c7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = { 'Cntrl': gen_cluster_labels(tblStayGap) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed21417-0e47-4396-b408-d7d179e5da33",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_stats(labels['Cntrl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179241f0-352b-4c2b-ac55-e5f7a937afd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "element = labels['Cntrl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating DataFrame from the dictionary\n",
    "frames = []\n",
    "for key, values in element.items():\n",
    "    temp_df = pd.DataFrame({'ClientId': values, 'ListNumber': key})\n",
    "    frames.append(temp_df)\n",
    "\n",
    "Labels_df = pd.concat(frames).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Labels_df = Labels_df.sort_values(by='ClientId').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6da1136-1684-4a7e-82a0-f4f08cc568ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clusters(tbl,labels):\n",
    "    \n",
    "    plt.rcParams['font.size'] = 16\n",
    "    fig,ax = plt.subplots(figsize=(16,12))\n",
    "    \n",
    "    colors = { 'Trn': '#919191', 'Epi': '#474747', 'Chr': '#c7c7c7' }\n",
    "    \n",
    "    for k in labels.keys():\n",
    "        plt.plot(tbl.loc[labels[k]].NEpisodes.to_numpy(),tbl.loc[labels[k]].NStays.to_numpy(),color=colors[k],marker='o',ls='None',label=k)\n",
    "    plt.xlabel('Total Number of Episodes',fontsize=16)\n",
    "    plt.ylabel('Total Number of Stays',fontsize=16)\n",
    "    plt.legend(fontsize=16)\n",
    "    #plt.savefig('ClusterResults.eps')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1572b7f3-228d-4708-912d-6d58418edee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clusters(tblStayGap,labels['Cntrl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e96016-3249-4b3e-8b74-045b6cdc9f18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835615e6-677e-4c11-9259-3f75f6ab2293",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7ad0a17-65e3-4e20-acac-3554bf7b83b0",
   "metadata": {},
   "source": [
    "## Centralized Model for Chronic Shelter Use Prediction\n",
    "---\n",
    "- A simple threshold based model for the first $T_O$ days in shelter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9bb749-4525-4cf2-a40e-19693e05316b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tO = 120 # Model observation window (days)\n",
    "seed = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c858369f-4f65-46a5-a22e-5f16087373b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tbl.groupby('ClientId').progress_apply(lambda x: ((x.Date - x.Date.min()).dt.days.drop_duplicates() < tO).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e127d4e1-6a21-4bd7-8536-b5f08cb11807",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x.index.isin(labels['Cntrl']['Chr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de3234e-2d13-4fc5-a510-34c4c7d62135",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainIdx, testIdx = next( StratifiedShuffleSplit(n_splits=1,test_size=0.3,random_state=seed).split(x,y) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490948a1-3ca9-481d-a0ea-76b84d67310d",
   "metadata": {},
   "source": [
    "#### Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871adb59-31b0-4621-bdfb-fef6b57e73da",
   "metadata": {},
   "outputs": [],
   "source": [
    "thrshVals = np.arange(5,85,dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96935298-0c01-4383-b7af-42fa7cf8ad52",
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrn = x.to_numpy()[trainIdx]\n",
    "yTrn = y[trainIdx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8edfb0-0ad9-44af-8c15-ffa8ccdbb0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(x,y,thrsh):\n",
    "    hat = x >= thrsh    \n",
    "    \n",
    "    cMtx = np.zeros((2,2),dtype='int')\n",
    "    cMtx[0,0] = (hat & y).sum()  # True Positives\n",
    "    cMtx[0,1] = (hat & ~y).sum() # False Positives\n",
    "    cMtx[1,0] = (~hat & y).sum() # False Negatives\n",
    "    cMtx[1,1] = (~hat & ~y).sum() # True Negatives   \n",
    "    \n",
    "    return cMtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf024b8-3f68-421e-87d7-4b6451b9b643",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_performance(cMtx):\n",
    "    tP,fP,fN,tN = cMtx[0,0],cMtx[0,1],cMtx[1,0],cMtx[1,1]\n",
    "    precision = tP/(tP+fP)\n",
    "    recall = tP/(tP+fN)\n",
    "    fscore = 2*tP/(2*tP+fN+fP)\n",
    "    return precision,recall,fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea1ea59-1837-462d-9fe6-4682611acbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_hyperparameters(x,y,nSplit):\n",
    "    precision = np.zeros((nSplit,len(thrshVals)))\n",
    "    recall = np.zeros((nSplit,len(thrshVals)))\n",
    "    fscore = np.zeros((nSplit,len(thrshVals)))\n",
    "\n",
    "    for i,(iSpltTrn,iSpltVal) in enumerate(StratifiedKFold(n_splits=5,shuffle=True,random_state=seed).split(x,y)):\n",
    "\n",
    "        # No training since it's just a threshold test.\n",
    "\n",
    "        # Validate hyperparameter settings (ie. the threshold value)\n",
    "        for j,thrsh in enumerate(thrshVals):\n",
    "            cMtx = evaluate_model(x[iSpltVal],y[iSpltVal],thrsh)\n",
    "            tP,fP,fN,tN = cMtx[0,0],cMtx[0,1],cMtx[1,0],cMtx[1,1]\n",
    "            precision[i,j],recall[i,j],fscore[i,j] = calc_performance(cMtx)\n",
    "\n",
    "    precision = precision.mean(axis=0)\n",
    "    recall = recall.mean(axis=0)\n",
    "    fscore = fscore.mean(axis=0)\n",
    "\n",
    "    iBest = np.argmax(fscore)\n",
    "\n",
    "    print(f'Best Threshold: {thrshVals[iBest]} (Precision: {precision[iBest]:.3f}, Recall: {recall[iBest]:.3f}, FScore: {fscore[iBest]:.3f}')\n",
    "    \n",
    "    return thrshVals[iBest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7defa576-b2fd-4e01-b489-84e19df98bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestThrsh = tune_hyperparameters(xTrn,yTrn,nSplit=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a70600-48e3-4dc4-8a80-a33fee729ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c97a12f-a9df-4b7a-b9d3-324c26c8887d",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15658edc-e05a-47a7-ac4a-4b8e52250c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "xTest = x.to_numpy()[testIdx]\n",
    "yTest = y[testIdx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2016f9-65ef-4e23-9713-e03ea705b2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cMtx = evaluate_model(xTest,yTest,bestThrsh)\n",
    "precision,recall,fscore = calc_performance(cMtx)\n",
    "print(f'Test Performance - Precision: {precision:.3f}, Recall: {recall:.3f}, FScore: {fscore:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbddd8c-d420-47cd-bd0b-c71ce81858ba",
   "metadata": {},
   "source": [
    "## Labelling at Individual Shelters\n",
    "---\n",
    "- Assume the centralized labels are the ground truth and compare how close labels generated in each shelter get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nShelters = tbl['Agency'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64192482-ab66-4b0b-a14e-904aed809238",
   "metadata": {},
   "outputs": [],
   "source": [
    "for shelter in nShelters:\n",
    "    \n",
    "    print(f'\\n--- Shelter {shelter} ---')\n",
    "    tblStayGapShelter = tbl[tbl.Agency == shelter].groupby('ClientId').apply(calc_stays_and_gaps)\n",
    "    labels[shelter] = gen_cluster_labels(tblStayGapShelter)      \n",
    "    \n",
    "    print(f'{len(tblStayGapShelter.index)} people.')\n",
    "    cluster_stats(labels[shelter])\n",
    "    \n",
    "    tP = np.isin(labels[shelter]['Chr'],labels['Cntrl']['Chr']).sum()\n",
    "    fP = (~np.isin(labels[shelter]['Chr'],labels['Cntrl']['Chr'])).sum()\n",
    "    fN = np.isin(labels[shelter]['Epi'],labels['Cntrl']['Chr']).sum() + np.isin(labels[shelter]['Trn'],labels['Cntrl']['Chr']).sum()\n",
    "    \n",
    "    print(f'Precision: {tP/(tP+fP):.3f}, Recall: {tP/(tP+fN):.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5cf1dd-7664-473e-baaf-d2e8a3ab8cb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab073d8a-2acd-4ba4-8517-c49b81b7be7d",
   "metadata": {},
   "source": [
    "## Chronic Shelter Use Prediction at Individual Shelters\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf06bd1d-4230-4e59-87d7-e7ae556acacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for shelter in nShelters:\n",
    "    \n",
    "    print(f'\\n--- Shelter {shelter} ---')\n",
    "    \n",
    "    x = tbl.loc[tbl.Agency==shelter].groupby('ClientId').apply(lambda x: ((x.Date - x.Date.min()).dt.days.drop_duplicates() < tO).sum())\n",
    "    \n",
    "    # Select hyperparameters with labels available in shelter.\n",
    "    y = x.index.isin(labels[shelter]['Chr'])\n",
    "    trainIdx, testIdx = next( StratifiedShuffleSplit(n_splits=1,test_size=0.3,random_state=seed).split(x,y) )    \n",
    "    \n",
    "    xTrn = x.to_numpy()[trainIdx]\n",
    "    yTrn = y[trainIdx]    \n",
    "    bestThrsh = tune_hyperparameters(xTrn,yTrn,nSplit=5)    \n",
    "    \n",
    "    # Test with the centralized labels.\n",
    "    y = x.index.isin(labels['Cntrl']['Chr'])    \n",
    "    xTest = x.to_numpy()[testIdx]\n",
    "    yTest = y[testIdx]\n",
    "    \n",
    "    cMtx = evaluate_model(xTest,yTest,bestThrsh)\n",
    "    precision,recall,fscore = calc_performance(cMtx)\n",
    "    print(f'Test Performance - Precision: {precision:.3f}, Recall: {recall:.3f}, FScore: {fscore:.3f}')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Find the total time frame.\n",
    "\n",
    "\n",
    "\n",
    "Step 2: Implement Windowing for like 4 months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming tbl is your DataFrame\n",
    "tbl['Date'] = pd.to_datetime(tbl['Date'])\n",
    "\n",
    "def filter_group(group):\n",
    "    group = group.sort_values('Date')\n",
    "    min_date = group['Date'].min()\n",
    "    # Keep only dates within the first 90 days\n",
    "    group = group[group['Date'] <= min_date + pd.Timedelta(days=Data_Days)]\n",
    "    # Drop duplicates in the Date column\n",
    "    group = group.drop_duplicates(subset='Date', keep=False)\n",
    "    return group\n",
    "\n",
    "filtered_tbl = tbl.groupby('ClientId').apply(filter_group).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b2eba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "episodeGap = 30 # days\n",
    "\n",
    "def calc_stays_and_gaps(tbl):    \n",
    "    stayDates = tbl.Date.drop_duplicates().sort_values() \n",
    "    nStay = len(stayDates)\n",
    "\n",
    "    gapVals = stayDates.diff()\n",
    "    nEpi = len(gapVals.loc[gapVals >= pd.Timedelta(f'{episodeGap} day') ])+1\n",
    "    \n",
    "    return pd.Series({ 'NStays': nStay, 'NEpisodes': nEpi })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17e93d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_tbl_2 = filtered_tbl.groupby('ClientId').progress_apply(calc_stays_and_gaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_tbl['Sleep'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def aggregate_to_30_day_windows(group):\n",
    "    group.set_index('Date', inplace=True)\n",
    "    # Initialize an empty DataFrame to store the final result for this group\n",
    "    final_group = pd.DataFrame()\n",
    "    calculated_freq = f'{int(Data_Days/Data_periods)}D'\n",
    "    # Create periods of 30 days each, starting from the minimum date\n",
    "    for period_start in pd.date_range(start=group.index.min(), periods=Data_periods, freq=calculated_freq):\n",
    "        # Define the end of the period (30 days after the start)\n",
    "        period_end = period_start + pd.Timedelta(days=Data_Days/Data_periods)\n",
    "        # Filter the group for events within the current 30-day period\n",
    "        events_in_period = group[(group.index >= period_start) & (group.index < period_end)]\n",
    "        # Count the number of events in the period\n",
    "        event_count = len(events_in_period)\n",
    "        # Add a row with the count of events and the correct ClientId\n",
    "        count_row = pd.DataFrame({'Sleep': [event_count]}, index=[period_start])\n",
    "        final_group = final_group.append(count_row)\n",
    "    final_group['ClientId'] = group.name  # Add the ClientId to each row\n",
    "    return final_group\n",
    "\n",
    "# Assuming filtered_tbl is your pre-filtered DataFrame\n",
    "aggregated_tbl = filtered_tbl.groupby('ClientId').apply(aggregate_to_30_day_windows).reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7a4f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will create a series from 0, 1, 2, 0, 1, 2, etc.\n",
    "helper_column = (aggregated_tbl.groupby('ClientId').cumcount() + 1).astype(str)\n",
    "\n",
    "# Add this as a new column to the DataFrame\n",
    "aggregated_tbl['CountId'] = 'Sleep_' + helper_column\n",
    "\n",
    "# Pivot the table\n",
    "pivot_table = aggregated_tbl.pivot(index='ClientId', columns='CountId', values='Sleep')\n",
    "\n",
    "# Reset the index to turn ClientId into a column\n",
    "pivot_table.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_clients = filtered_tbl.drop_duplicates(subset='ClientId', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set ClientId as index for easy lookup\n",
    "pivot_table.set_index('ClientId', inplace=True)\n",
    "unique_clients.set_index('ClientId', inplace=True)\n",
    "\n",
    "# Update Agency in agg_tbl based on unique_clients\n",
    "pivot_table['Agency'] = pivot_table.index.map(unique_clients['Agency'])\n",
    "\n",
    "# Reset index if you want ClientId as a column\n",
    "pivot_table.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine Shelters over ClientID\n",
    "\n",
    "Run a model in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9d8899-2e65-417f-bf27-f7dfdf2acc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table = pivot_table.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd3b731",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_clients.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4486ef3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_tbl_2.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7d41f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table['Episodes'] = filtered_tbl_2['NEpisodes']\n",
    "pivot_table['Stays'] = filtered_tbl_2['NStays']\n",
    "pivot_table['Agency'] = unique_clients['Agency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save aggregated_tbl as a CSV file\n",
    "file_name = f'CHF_Data_1/CHF_{Data_Days}D_{Data_periods}W.csv'\n",
    "pivot_table.to_csv(file_name, index=False)\n",
    "\n",
    "# # # Save Labels_df as a CSV file\n",
    "file_name = f'CHF_Data_1/CHF_Labels_{LDays}.csv'\n",
    "Labels_df.to_csv(file_name, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
