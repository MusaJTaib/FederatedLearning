{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_periods = 10\n",
    "Data_Days = 90\n",
    "LDays = 548"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agency No: 4,12,55,188,213,225,330,333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"Centralized_FL\"\n",
    "windows = f'{Data_periods}W'\n",
    "label_days = f'{Data_Days}-Central'\n",
    "prediction_days = f'{LDays}'\n",
    "Agency_no = 330"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "CHF_data = pd.read_csv(f'CHF_Data_1/CHF_Unlinked_{Data_Days}D_{Data_periods}W.csv')\n",
    "CHF_Labels_2 = pd.read_csv(f'CHF_Data_1/CHF_Labels_Local_{LDays}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHF_data = CHF_data[CHF_data['Agency'] == Agency_no]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter CHF_Labels to keep only those rows where ClientId exists in CHF_data\n",
    "CHF_Labels_2 = CHF_Labels_2[CHF_Labels_2['ClientId'].isin(CHF_data['ClientId'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHF_Labels = pd.DataFrame()\n",
    "CHF_Labels['ClientId'] = CHF_Labels_2['ClientId'] \n",
    "CHF_Labels['Label'] = CHF_Labels_2['ListNumber']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted_data = CHF_data.drop('Agency', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge and preprocess data\n",
    "data = pd.merge(pivoted_data, CHF_Labels, on='ClientId')\n",
    "data['Label'] = data['Label'].map({'Trn': 0, 'Epi': 1, 'Chr': 2})  # Replace class1, class2, class3 with actual class names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "y_indices  = pd.DataFrame()\n",
    "X = data.drop(['Label'], axis=1) #.values\n",
    "y_indices ['Label'] = data['Label']\n",
    "y_indices ['ClientId'] = data['ClientId']\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train2, X_test, y_train2, y_test = train_test_split(\n",
    "    X, \n",
    "    y_indices, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y_indices['Label']  # This ensures the stratification\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train2, \n",
    "    y_train2, \n",
    "    test_size=0.15, \n",
    "    random_state=42, \n",
    "    stratify=y_train2['Label']  # This ensures the stratification\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHF_Labels_3A1 = pd.read_csv(f'CHF_Data_1/CHF_Labels_{LDays}.csv')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHF_Labels_3A = pd.DataFrame()\n",
    "CHF_Labels_3A['ClientId'] = CHF_Labels_3A1['ClientId'] \n",
    "CHF_Labels_3A['Label'] = CHF_Labels_3A1['ListNumber']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHF_Labels_3B1 = pd.read_csv(f'CHF_Data_1/CHF_Labels_FL2_{LDays}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHF_Labels_3B = pd.DataFrame()\n",
    "CHF_Labels_3B['ClientId'] = CHF_Labels_3B1['Value'] \n",
    "CHF_Labels_3B['Label'] = CHF_Labels_3B1['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Split ClientId in CHF_Labels_3B to extract IntegerA\n",
    "CHF_Labels_3B['IntegerA'] = CHF_Labels_3B['ClientId'].apply(lambda x: x.split('_')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHF_Labels_3A['ClientId'] = CHF_Labels_3A['ClientId'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(CHF_Labels_3B, CHF_Labels_3A.rename(columns={'Label': 'Label_3A'}), \n",
    "                     left_on='IntegerA', right_on='ClientId', how='left')\n",
    "\n",
    "# Step 4: Update Label in CHF_Labels_3B with Label from CHF_Labels_3A where there's a match\n",
    "CHF_Labels_3B['Label'] = merged_df['Label_3A']\n",
    "\n",
    "# Step 5: Drop the temporary columns\n",
    "CHF_Labels_3B.drop(['IntegerA'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHF_Labels_4 = pd.DataFrame()\n",
    "CHF_Labels_4 = CHF_Labels_3B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHF_Labels_4['Label'] = CHF_Labels_4['Label'].map({'Trn': 0, 'Epi': 1, 'Chr': 2})  # Replace class1, class2, class3 with actual class names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.reset_index(drop=True,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test['ClientId'] = y_test['ClientId'].astype(str)  # Convert to int\n",
    "CHF_Labels_4['ClientId'] = CHF_Labels_4['ClientId'].astype(str)  # Ensure this is also int\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now perform the merge with CHF_Labels_3\n",
    "merged_df = y_test.merge(CHF_Labels_4[['ClientId', 'Label']], on='ClientId', how='left', suffixes=('', '_new'))\n",
    "\n",
    "\n",
    "merged_df.dropna(subset=['Label'], inplace=True)\n",
    "\n",
    "# Replace the 'Label' column in y_test_df with the 'Label' from CHF_Labels_3\n",
    "y_test['Label'] = merged_df['Label_new']\n",
    "y_test.dropna(subset=['Label'], inplace=True)\n",
    "\n",
    "# Drop rows where 'Label' is NaN if any such rows are not required\n",
    "#y_test_df.dropna(subset=['Label'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['ClientId'] = X_test['ClientId'].astype(str)  # Convert to string\n",
    "y_test['ClientId'] = y_test['ClientId'].astype(str)  # Ensure this is also str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.merge(y_test['ClientId'], on='ClientId', how='inner')\n",
    "X_test = X_test.drop_duplicates(subset='ClientId', keep='first')\n",
    "y_test = y_test.merge(X_test['ClientId'], on='ClientId', how='inner')\n",
    "y_test = y_test.drop_duplicates(subset='ClientId', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort X_test by ClientId\n",
    "X_test = X_test.sort_values(by='ClientId')\n",
    "\n",
    "# Sort y_test by ClientId\n",
    "y_test = y_test.sort_values(by='ClientId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.drop(['ClientId'], axis=1).values\n",
    "X_train = X_train.drop(['ClientId'], axis=1).values\n",
    "X_val = X_val.drop(['ClientId'], axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.fit_transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.drop(['ClientId'], axis=1).values\n",
    "y_train = y_train.drop(['ClientId'], axis=1).values\n",
    "y_val = y_val.drop(['ClientId'], axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.squeeze(y_train)\n",
    "y_test = np.squeeze(y_test)\n",
    "y_val = np.squeeze(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights_tensor = torch.tensor(np.array([0.75, 7, 6]), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train).float()\n",
    "y_train_tensor = torch.tensor(y_train).long()\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test).float()\n",
    "y_test_tensor = torch.tensor(y_test).long()\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val).float()\n",
    "y_val_tensor = torch.tensor(y_val).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Create DataLoaders\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 2048\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=True)\n",
    "#test_dataset = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_recall(outputs, labels, num_classes):\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    correct = preds.eq(labels.view_as(preds))\n",
    "\n",
    "    recall_per_class = []\n",
    "    for i in range(num_classes):\n",
    "        correct_class = correct[labels == i]\n",
    "        recall_class = torch.mean(correct_class.float()) if correct_class.numel() > 0 else torch.tensor(0)\n",
    "        recall_per_class.append(recall_class.item())\n",
    "\n",
    "    return recall_per_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def early_stopping_check(epoch_val_loss, best_val_loss, best_model_weights, model, patience_counter, patience=10):\n",
    "    if epoch_val_loss < best_val_loss:\n",
    "        best_val_loss = epoch_val_loss\n",
    "        best_model_weights = copy.deepcopy(model.state_dict())\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    stop_training = False\n",
    "    if patience_counter >= patience:\n",
    "        stop_training = True\n",
    "\n",
    "    return stop_training, best_val_loss, best_model_weights, patience_counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the MLP model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, 256),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.Dropout(0.50),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.Dropout(0.50),\n",
    "            nn.Linear(128, 8),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.Dropout(0.50),\n",
    "            nn.Linear(8, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "# Assuming the data loaders and class_weights_tensor are set up correctly\n",
    "# Hyperparameters\n",
    "input_size = X_train.shape[1]  # Number of features\n",
    "num_classes = 3  # Example number of classes\n",
    "batch_size = 250\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 200  # Number of epochs for training\n",
    "num_runs = 10  # Number of runs\n",
    "\n",
    "# Function to train and evaluate the model\n",
    "def train_and_evaluate_model(model, train_loader, test_loader, criterion, optimizer):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluate the model\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    precision = np.divide(cm.diagonal(), cm.sum(axis=0), out=np.zeros_like(cm.diagonal(), dtype=float), where=cm.sum(axis=0)!=0)\n",
    "    recall = np.divide(cm.diagonal(), cm.sum(axis=1), out=np.zeros_like(cm.diagonal(), dtype=float), where=cm.sum(axis=1)!=0)\n",
    "    return np.nanmean(precision), np.nanmean(recall), precision, recall\n",
    "\n",
    "# Initialize sums and arrays for averages\n",
    "sum_macro_avg_precision = 0\n",
    "sum_macro_avg_recall = 0\n",
    "sum_class_precision = np.zeros(num_classes)\n",
    "sum_class_recall = np.zeros(num_classes)\n",
    "\n",
    "# Main loop to train and evaluate the model multiple times\n",
    "for _ in range(num_runs):\n",
    "    model = MLP(input_size, num_classes)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    macro_avg_precision, macro_avg_recall, class_precision, class_recall = train_and_evaluate_model(model, train_loader, test_loader, criterion, optimizer)\n",
    "    sum_macro_avg_precision += macro_avg_precision\n",
    "    sum_macro_avg_recall += macro_avg_recall\n",
    "    sum_class_precision += class_precision\n",
    "    sum_class_recall += class_recall\n",
    "\n",
    "# Calculate averages\n",
    "average_macro_avg_precision = sum_macro_avg_precision / num_runs\n",
    "average_macro_avg_recall = sum_macro_avg_recall / num_runs\n",
    "average_class_precision = sum_class_precision / num_runs\n",
    "average_class_recall = sum_class_recall / num_runs\n",
    "\n",
    "print(f\"Average Macro Average Precision: {average_macro_avg_precision * 100:.2f}%\")\n",
    "print(f\"Average Macro Average Recall: {average_macro_avg_recall * 100:.2f}%\")\n",
    "for i in range(num_classes):\n",
    "    precision_str = f\"{average_class_precision[i] * 100:.2f}%\" if not np.isnan(average_class_precision[i]) else \"0.00%\"\n",
    "    recall_str = f\"{average_class_recall[i] * 100:.2f}%\"\n",
    "    print(f\"Average Precision for Class {i}: {precision_str}\")\n",
    "    print(f\"Average Recall for Class {i}: {recall_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary for DataFrame\n",
    "data = {\n",
    "    \"Model Type\": [model_type],\n",
    "    \"Agency\": [Agency_no],\n",
    "    \"Windows\": [windows],\n",
    "    \"Label Days\": [label_days],\n",
    "    \"Prediction Days\": [prediction_days],\n",
    "    \"Macro Average Precision\": [f\"{average_macro_avg_precision * 100:.2f}%\"],\n",
    "    \"Macro Average Recall\": [f\"{average_macro_avg_recall * 100:.2f}%\"],\n",
    "}\n",
    "\n",
    "# Adding per-class precision and recall with handling for NaN values\n",
    "for i in range(num_classes):\n",
    "    precision_str = f\"{average_class_precision[i] * 100:.2f}%\" if not np.isnan(average_class_precision[i]) else \"0.00%\"\n",
    "    recall_str = f\"{average_class_recall[i] * 100:.2f}%\" if not np.isnan(average_class_recall[i]) else \"0.00%\"\n",
    "    data[f\"Precision Class {i}\"] = [precision_str]\n",
    "    data[f\"Recall Class {i}\"] = [recall_str]\n",
    "\n",
    "# Creating a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame to verify\n",
    "print(df)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "filename = \"NRes/Model_Results_Local_3.csv\"\n",
    "df.to_csv(filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
